model:
  type: "SATRN"
  hidden_dim: 256
  n_e: 6
  n_d: 3
  num_head: 8
  dropout_rate: 0.1
loss:
  type: "CrossEntropyLoss"
optimizer:
  type: "Adam"
  lr: 5e-4
  weight_decay: 1e-4
scheduler:
  type: "get_cosine_with_hard_restarts_schedule_with_warmup"
  num_warmup_steps: 625 * 5
  num_training_steps: 625 * 50
  num_cycles: 3

data:
  train:
    path:
      - "/opt/ml/input/data/train_dataset/gt.txt"
    transforms:
      - "Resize(height=32, width=100)"
      - "Normalize(always_apply=True)"
  valid:
    path:
      - ""
    transforms:
      - null
  test:
    path:
      - ""
    transforms:
      - null
  token_paths:
    - "/opt/ml/input/data/train_dataset/tokens.txt"
  dataset_proportions:  # proportion of data to take from train (not test)
    - 1.0
  random_split: True  # if set True, divided to train and validation dataset from train path. valid args would be ignored.
  test_proportions: 0.2  # factor how many to take from train data for validation.
  crop: True
  rgb: True  # True for RGB, False for grayscale

train_config:
  batch_size: 128
  num_workers: 8
  num_epochs: 100
  print_interval: 1
  teacher_forcing_ratio: 0.5
  max_grad_norm: 2.0
  fp_16: False
seed: 42
wandb:
  project: "hangjoo"
  entity: "unnamed"
  name: "SATRN_small_fp16_test"
prefix: "./log/SATRN_small_test"
checkpoint: ""