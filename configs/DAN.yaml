model:
  type: "DAN"
  FE:
    strides: [[2, 2], [2, 2], [2, 1], [2, 2], [2, 2], [2, 1]]
    compress_layer: True
    input_shape: [1, 192, 2048]
  CAM:
    maxT: 150
    depth: 14
    num_channels: 128
  DTD:
    channel_num: 256
    dropout: 0.1
loss:
  type: "CrossEntropyLoss"
optimizer:
  type: "Adam"
  lr: 0.1
  momentum: 0.9
scheduler:
  type: "get_cosine_with_hard_restarts_schedule_with_warmup"
  num_warmup_steps: 1251 * 5
  num_training_steps: 1251 * 50
  num_cycles: 3

data:
  train:
    path:
      - "/opt/ml/input/data/train_dataset/gt_train_ours.txt"
    transforms:
      - "ToGray(p=1.0)"
      - "Resize(height=32, width=100)"
      - "Normalize(mean=0.5, std=0.5, always_apply=True)"
  valid:
    path:
      - "/opt/ml/input/data/train_dataset/gt_valid_ours.txt"
    transforms:
      - "ToGray(p=1.0)"
      - "Resize(height=32, width=100)"
      - "Normalize(mean=0.5, std=0.5, always_apply=True)"
  test:
    path:
      - ""
    transforms:
      - null
  token_paths:
    - "/opt/ml/input/data/train_dataset/tokens.txt"
  dataset_proportions:  # proportion of data to take from train (not test)
    - 1.0
  random_split: False  # if set True, divided to train and validation dataset from train path. valid args would be ignored.
  test_proportions: 0.2  # factor how many to take from train data for validation.
  rgb: True  # True for RGB, False for grayscale

train_config:
  batch_size: 192
  num_workers: 8
  num_epochs: 100
  print_interval: 1
  teacher_forcing_ratio: 0.5
  max_grad_norm: 2.0
  fp_16: True
seed: 42
wandb:
  project: "hangjoo"
  entity: "unnamed"
  name: "DAN"
prefix: "./log/DAN"
checkpoint: ""